{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te6W9TGOrpXC",
        "colab_type": "text"
      },
      "source": [
        "Part Seven:\n",
        "\n",
        "---\n",
        "Transfer Learning\n",
        "*   Load Spectrogram Images & Encode the Labels\n",
        "*   Split Data into Training, Testing & Validation Data\n",
        "*   Import VGG16 Model & Modify Accordingly\n",
        "*   Classify with Modified VGG16 Model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxBldWd1rvQ2",
        "colab_type": "text"
      },
      "source": [
        "**Import Headers**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gle_BTcuq3nS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pickle as pkl\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print (\"TensorFlow version: \" + tf.__version__)\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn import metrics\n",
        "from tensorflow.contrib.keras import layers\n",
        "from tensorflow.contrib.keras import models\n",
        "from tensorflow.contrib.keras import layers\n",
        "from tensorflow.contrib.keras import optimizers\n",
        "from tensorflow.contrib.keras import callbacks\n",
        "from tensorflow.contrib.keras import regularizers\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJC-vS-c2Qbt",
        "colab_type": "text"
      },
      "source": [
        "**Load Spectrogram Images & List Genres**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXlGhyFN2P2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/Project/Data/Working_Data/Image.pickle','rb') as f:\n",
        "    x = pkl.load(f)\n",
        "with open('/content/drive/My Drive/Project/Data/Working_Data/Genre.pickle','rb') as f:\n",
        "    y = pkl.load(f)\n",
        "genres = os.listdir(\"/content/drive/My Drive/Project/Data/Working_Data/Spectogram_Images\")\n",
        "print(\"The list of genres are:\",genres)\n",
        "le = preprocessing.LabelEncoder()\n",
        "y_label_encoded = le.fit_transform(y)\n",
        "cl_weight = compute_class_weight(class_weight = 'balanced', classes = np.unique(y_label_encoded), y = y_label_encoded)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCvz9gSW4JH-",
        "colab_type": "text"
      },
      "source": [
        "**Split Data into Train, Test & Validation Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAMAatkj57UU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y_label_encoded, test_size=0.2, random_state=20)\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=20)\n",
        "print(\"The shape of x-train is:\",X_train.shape)\n",
        "print(\"The shape of y-train is:\",Y_train.shape)\n",
        "print(\"The shape of x-test is:\",X_test.shape)\n",
        "print(\"The shape of y-test is:\",Y_test.shape)\n",
        "print(\"The shape of x-validation is:\",X_val.shape)\n",
        "print(\"The shape of y_validation is:\",Y_val.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEkiMMK96Om1",
        "colab_type": "text"
      },
      "source": [
        "**Import VGG16 Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTdK1e--6TAo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conv_base = tf.contrib.keras.applications.VGG16(include_top = False, weights = 'imagenet', input_shape = (288, 432, 3))\n",
        "print(\"Original VGG16 Model Summary:\")\n",
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90TDTpgq6rpL",
        "colab_type": "text"
      },
      "source": [
        "**Modify VGG16 Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_zaWHTj6uT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 32\n",
        "L2_LAMBDA = 0.001\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten()) #Flatten output and send it to MLP\n",
        "#1-layer MLP with Dropout\n",
        "model.add(layers.Dense(512, name='dense_1', kernel_regularizer=regularizers.l2(L2_LAMBDA)))\n",
        "model.add(layers.Dropout(rate=0.3, name='dropout_1')) #Can try varying dropout rates\n",
        "model.add(layers.Activation(activation='relu', name='activation_1'))\n",
        "model.add(layers.Dense(NUM_CLASSES, activation='softmax', name='dense_output'))\n",
        "conv_base.trainable = False\n",
        "print(\"Modified VGG16 Model Summary:\")\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHhvlt5W7IBz",
        "colab_type": "text"
      },
      "source": [
        "**Classify with Modified VGG16 Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngjbW_3e7LgX",
        "colab_type": "text"
      },
      "source": [
        "*Function to Generate Batches*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-NoSNNA7Wf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator(X,Y, BATCH_SIZE):\n",
        "    L = len(Y)\n",
        "    while True:\n",
        "        batch_start = 0\n",
        "        batch_end = BATCH_SIZE\n",
        "        while batch_start < L:\n",
        "            limit = min(batch_end, L)\n",
        "            X_file_list = X[batch_start : limit]\n",
        "            Y_file_list = Y[batch_start : limit]\n",
        "            batch_img_array, batch_label_array = (X_file_list,Y_file_list)\n",
        "            yield (batch_img_array, batch_label_array)     \n",
        "            batch_start += BATCH_SIZE   \n",
        "            batch_end += BATCH_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5K-9mIUGA5G",
        "colab_type": "text"
      },
      "source": [
        "*Function to Draw Confusion Matrix*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jL3_jBn6Guez",
        "colab": {}
      },
      "source": [
        "def draw_confusion_matrix(y_test,y_pred,epochs):\n",
        "  cm = metrics.confusion_matrix(y_test, y_pred)\n",
        "  plt.figure(figsize=(9,9))\n",
        "  sns.heatmap(cm, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues');\n",
        "  plt.ylabel('Actual label');\n",
        "  plt.xlabel('Predicted label');\n",
        "  title = 'Transfer Learning with VGG16 Model for '+str(epochs)+' epochs'\n",
        "  plt.title(title, size = 15);\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnoDzzmZ7d-A",
        "colab_type": "text"
      },
      "source": [
        "*Compile & Train the Model for 10 epochs*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa3RM-X37hJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "STEPS_PER_EPOCH = len(Y_train)//BATCH_SIZE\n",
        "VAL_STEPS = len(Y_val)//BATCH_SIZE\n",
        "history = model.fit_generator(generator = batch_generator(X_train, Y_train, BATCH_SIZE), epochs = 10, steps_per_epoch = STEPS_PER_EPOCH, class_weight = cl_weight,\n",
        "                              validation_data = batch_generator(X_val, Y_val, BATCH_SIZE), validation_steps = VAL_STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdLNutsx8LQq",
        "colab_type": "text"
      },
      "source": [
        "*Plot the Training & Validation Curve*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vpbazda8MLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d = history.history\n",
        "training_loss = d['loss']\n",
        "validation_loss = d['val_loss']\n",
        "plt.plot(training_loss, label = 'Train Loss')\n",
        "plt.plot(validation_loss, label = 'Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gv229Jo28Vyc",
        "colab_type": "text"
      },
      "source": [
        "*Calculate Accuracy of the Model & Print the Confusion Matrix*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i5izfaM8Wqa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "y_test = Y_test\n",
        "y_pred = []\n",
        "c=0\n",
        "for i in range(len(Y_pred)):\n",
        "    y_pred.append(np.argmax(Y_pred[i]))\n",
        "    if(np.argmax(Y_pred[i]) == Y_test[i]):\n",
        "        c+=1\n",
        "accuracy = c/len(Y_pred) * 100\n",
        "print(\"The accuracy is:\",str(accuracy),\"%.\")\n",
        "draw_confusion_matrix(y_test, y_pred,10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VeHZyO42yAHg"
      },
      "source": [
        "*Compile & Train the Model for 100 epochs*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cYWDBknPyHWm",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
        "STEPS_PER_EPOCH = len(Y_train)//BATCH_SIZE\n",
        "VAL_STEPS = len(Y_val)//BATCH_SIZE\n",
        "history = model.fit_generator(generator = batch_generator(X_train, Y_train, BATCH_SIZE), epochs = 100, steps_per_epoch = STEPS_PER_EPOCH, class_weight = cl_weight,\n",
        "                              validation_data = batch_generator(X_val, Y_val, BATCH_SIZE), validation_steps = VAL_STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "e6MmpYkgiO6e"
      },
      "source": [
        "*Plot the Training & Validation Curve*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "snURBV6NioN0",
        "colab": {}
      },
      "source": [
        "d = history.history\n",
        "training_loss = d['loss']\n",
        "validation_loss = d['val_loss']\n",
        "plt.plot(training_loss, label = 'Train Loss')\n",
        "plt.plot(validation_loss, label = 'Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QBDcKtjIivYd"
      },
      "source": [
        "*Calculate Accuracy of the Model & Print the Confusion Matrix*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ar0no8-Gi8bX",
        "colab": {}
      },
      "source": [
        "Y_pred = model.predict(X_test)\n",
        "y_test = Y_test\n",
        "y_pred = []\n",
        "c=0\n",
        "for i in range(len(Y_pred)):\n",
        "    y_pred.append(np.argmax(Y_pred[i]))\n",
        "    if(np.argmax(Y_pred[i]) == Y_test[i]):\n",
        "        c+=1\n",
        "accuracy = c/len(Y_pred) * 100\n",
        "print(\"The accuracy is:\",str(accuracy),\"%.\")\n",
        "draw_confusion_matrix(y_test, y_pred,100)\n",
        "print(\"Part Seven Successful!\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}